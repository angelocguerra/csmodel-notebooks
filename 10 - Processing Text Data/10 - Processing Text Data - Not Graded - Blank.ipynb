{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69eaf071",
   "metadata": {},
   "source": [
    "# Processing Text Data\n",
    "In this Notebook, we will be processing text data using the [Twitter Customer Support](https://www.kaggle.com/datasets/thoughtvector/customer-support-on-twitter). \n",
    "\n",
    "Our Notebooks in CSMODEL are designed to be guided learning activities. To use them, simply go through the cells from top to bottom, following the directions along the way. If you find any unclear parts or mistakes in the Notebooks, email your instructor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbfb824",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "* Read each cell and implement the TODOs sequentially. The markdown/text cells also contain instructions which you need to follow to get the whole notebook working.\n",
    "* Do not change the variable names unless the instructor allows you to.\n",
    "* You are expected to search how to some functions work on the Internet or via the docs. \n",
    "* The notebooks will undergo a 'Restart and Run All' command, so make sure that your code is working properly.\n",
    "* You are expected to understand the dataset loading and processing separately from this class.\n",
    "* You may not reproduce this notebook or share them to anyone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749cfc92",
   "metadata": {},
   "source": [
    "## Import\n",
    "Import **numpy**, **pandas**, **re**, **nltk**, and **string**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0a925b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7885811",
   "metadata": {},
   "source": [
    "## Twitter Customer Support Dataset\n",
    "For this notebook, we will work on a reduced version of the dataset called `Twitter Customer Support`. The original dataset contains more than 2M rows. In our reduced version, we only retained the first 50k rows in the dataset.\n",
    "\n",
    "The dataset is provided to you as a `.csv` file. `.csv` means comma-separated values. You can open the file in Notepad to see how it is exactly formatted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b95a64",
   "metadata": {},
   "source": [
    "If you view the `.csv` file in Excel, you can see that our dataset contains 50k **observations** (rows) across 7 **variables** (columns). The following are the descriptions of each variable in the dataset.\n",
    "\n",
    "- **`tweet_id`**: A unique, anonymized ID for the Tweet. Referenced by `response_tweet_id` and `in_response_to_tweet_id`.\n",
    "- **`author_id`**: A unique, anonymized user ID. @s in the dataset have been replaced with their associated anonymized user ID.\n",
    "- **`inbound`**: Whether the tweet is \"inbound\" to a company doing customer support on Twitter. This feature is useful when re-organizing data for training conversational models.\n",
    "- **`created_at`**: Date and time when the tweet was sent.\n",
    "- **`text`**: Tweet content. Sensitive information like phone numbers and email addresses are replaced with mask values like `__email__`.\n",
    "- **`response_tweet_id`**: IDs of tweets that are responses to this tweet, comma-separated.\n",
    "- **`in_response_to_tweet_id`**: ID of the tweet this tweet is in response to, if any."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b91a53c",
   "metadata": {},
   "source": [
    "Let's read the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc1ea731",
   "metadata": {},
   "outputs": [],
   "source": [
    "twcs_df = pd.read_csv('twcs-reduced.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c469afbb",
   "metadata": {},
   "source": [
    "Show the first few rows of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1c9d717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id   author_id  inbound                      created_at  \\\n",
       "0         1  sprintcare    False  Tue Oct 31 22:10:47 +0000 2017   \n",
       "1         2      115712     True  Tue Oct 31 22:11:45 +0000 2017   \n",
       "2         3      115712     True  Tue Oct 31 22:08:27 +0000 2017   \n",
       "3         4  sprintcare    False  Tue Oct 31 21:54:49 +0000 2017   \n",
       "4         5      115712     True  Tue Oct 31 21:49:35 +0000 2017   \n",
       "\n",
       "                                                text response_tweet_id  \\\n",
       "0  @115712 I understand. I would like to assist y...                 2   \n",
       "1      @sprintcare and how do you propose we do that               NaN   \n",
       "2  @sprintcare I have sent several private messag...                 1   \n",
       "3  @115712 Please send us a Private Message so th...                 3   \n",
       "4                                 @sprintcare I did.                 4   \n",
       "\n",
       "   in_response_to_tweet_id  \n",
       "0                      3.0  \n",
       "1                      1.0  \n",
       "2                      4.0  \n",
       "3                      5.0  \n",
       "4                      6.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twcs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4569b0",
   "metadata": {},
   "source": [
    "For this notebook, we will use the values under the `text` column. Thus, let's instantiate a new `DataFrame` with only the `text` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f15a6ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "twcs_text_df = twcs_df[['text']]\n",
    "twcs_text_df['text'] = twcs_text_df['text'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6ea9c7",
   "metadata": {},
   "source": [
    "Display the first few rows of `twcs_text_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc3b7f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sprintcare I did.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  @115712 I understand. I would like to assist y...\n",
       "1      @sprintcare and how do you propose we do that\n",
       "2  @sprintcare I have sent several private messag...\n",
       "3  @115712 Please send us a Private Message so th...\n",
       "4                                 @sprintcare I did."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twcs_text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea4ee2a",
   "metadata": {},
   "source": [
    "## Pre-Processing Text Data\n",
    "\n",
    "In any machine learning task, preprocessing the data is as important as model building. This process is even more important for unstructured data like texts. In this notebook, we will be performing some of the most common text pre-processing steps including:\n",
    "\n",
    "* Lower casing\n",
    "* Removal of Punctuations\n",
    "* Removal of Stopwords\n",
    "* Removal of Frequent words\n",
    "* Stemming\n",
    "* Lemmatization\n",
    "\n",
    "\n",
    "Do note that all of these pre-processing steps need not be performed on the dataset all the time. You need to carefully identify appropriate pre-processing techniques depending on the data or the task. For example, emojis or emoticons might be useful in sentiment analysis, thus it might not be a good idea to remove them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba5ec0a",
   "metadata": {},
   "source": [
    "Open `text_preprocessor.py` file. Some of the functions in the file are not yet implemented. We will implement the missing functions of this file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b172a559",
   "metadata": {},
   "source": [
    "### Lower Casing\n",
    "\n",
    "Lower casing converts the input text into the same case so that 'text', 'Text', and 'TEXT' are similarly treated. This is especially helpful in getting the correct frequency of the same word but are represented in different cases. However, this may not be helpful when performing Part-of-Speech tagging (where proper casing gives some information about Nouns and so on) or sentiment analysis (where upper casing refers to anger and so on).\n",
    "\n",
    "By default, lower casing is done my most of the modern day vectorizers and tokenizers like [sklearn TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html). Thus, set them to `False` as needed depending on the use case. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c5002f",
   "metadata": {},
   "source": [
    "Open `text_preprocessor.py` file and complete the `to_lower_case()` function. This converts characters in each string of a Series to lower case.\n",
    "\n",
    "Implement the `to_lower_case()` function. Inline comments should help you in completing the contents of the function.\n",
    "\n",
    "Afterwards, let's import the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a1bc8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "import text_preprocessor as tp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3227620d",
   "metadata": {},
   "source": [
    "Convert the texts in column `text` to lowercase by calling the function `to_lower_case()` and assign the return value to a new column `text_lower`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfd0ccd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "text_lower = tp.to_lower_case(twcs_text_df['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59a673d",
   "metadata": {},
   "source": [
    "Let's display the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fe7d7ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sprintcare I did.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  @115712 I understand. I would like to assist y...\n",
       "1      @sprintcare and how do you propose we do that\n",
       "2  @sprintcare I have sent several private messag...\n",
       "3  @115712 Please send us a Private Message so th...\n",
       "4                                 @sprintcare I did."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twcs_text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01003f3",
   "metadata": {},
   "source": [
    "Display the lowercase version of the string in index `10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "322fd5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@sprintcare since i signed up with you....since day 1'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here\n",
    "text_lower.loc[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fe8b0a",
   "metadata": {},
   "source": [
    "**Checkpoint #1:** After calling the function `to_lower_case()`, what is the string in index `10`?\n",
    "\n",
    "Answer: @sprintcare since i signed up with you....since day 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a8aaa2",
   "metadata": {},
   "source": [
    "Display the lowercase version of the string in index `100`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40656435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@askplaystation so, what's the november ps plus free game?\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here\n",
    "text_lower.loc[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b13cc7",
   "metadata": {},
   "source": [
    "**Checkpoint #2:** After calling the function `to_lower_case()`, what is the string in index `100`?\n",
    "\n",
    "Answer: @askplaystation so, what's the november ps plus free game?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9acb7ec",
   "metadata": {},
   "source": [
    "### Removal of Punctuations\n",
    "\n",
    "Removing punctuations also standardizes the text data. This will treat the words 'hurray!' and 'hurray' in the same way. The list of punctuations to include should depend on the use case. For example, the `string.punctuation` in python contains the following punctuation symbols:\n",
    "\n",
    "``!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~``\n",
    "\n",
    "Add or remove punctuations depending on the use case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66615be",
   "metadata": {},
   "source": [
    "Get the punctuations in `string.punctuation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89da408d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "punctuations = string.punctuation\n",
    "print(punctuations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5d4610",
   "metadata": {},
   "source": [
    "Open `text_preprocessor.py` file and complete the `remove_punctuations()` function. This takes in a `Series` of strings and removes punctuations in the text.\n",
    "\n",
    "Implement the `remove_punctuations()` function. Inline comments should help you in completing the contents of the function.\n",
    "\n",
    "Afterwards, let's import the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99a8cb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "from text_preprocessor import remove_punctuations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00e6a9a",
   "metadata": {},
   "source": [
    "Remove punctuations in the texts in column `text_lower` by calling the function `remove_punctuations()` and assign the return value to a new column `text_wo_punct`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95837366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "text_wo_punct = tp.remove_punctuations(text_lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f902bd5",
   "metadata": {},
   "source": [
    "Let's display the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efb14513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sprintcare I did.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  @115712 I understand. I would like to assist y...\n",
       "1      @sprintcare and how do you propose we do that\n",
       "2  @sprintcare I have sent several private messag...\n",
       "3  @115712 Please send us a Private Message so th...\n",
       "4                                 @sprintcare I did."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twcs_text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d48a42",
   "metadata": {},
   "source": [
    "Display the string without punctuations in index `300`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0a0f4c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mcdonalds treat'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here\n",
    "text_wo_punct[300]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fda709",
   "metadata": {},
   "source": [
    "**Checkpoint #3:** After calling the function `remove_punctuations()`, what is the string in index `300`?\n",
    "\n",
    "Answer: mcdonalds treat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfb904e",
   "metadata": {},
   "source": [
    "Display the string without punctuations in index `1000`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5625da42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bofahelp whenever your ready'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here\n",
    "text_wo_punct[1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0522728",
   "metadata": {},
   "source": [
    "**Checkpoint #4:** After calling the function `remove_punctuations()`, what is the string in index `1000`?\n",
    "\n",
    "Answer: bofahelp whenever your ready"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50810cc",
   "metadata": {},
   "source": [
    "### Removal of Stopwords\n",
    "\n",
    "Stopwords are commonly occuring words in a language, which include 'the', 'a', among others. These words can be removed from the text most of the time since they do not provide valuable information for analysis. However, these words might be important when performing Part-of-Speech tagging.\n",
    "\n",
    "List of stopwords are already compiled for different languages. For example, the list of stopwords for the English language from the `nltk` package can be seen below.\n",
    "\n",
    "Let's download `stopwords` from the `nltk.corpus` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "064b8bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/angeloguerra/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff46597c",
   "metadata": {},
   "source": [
    "Import `stopwords` and print the stopwords in English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48014166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6421dc",
   "metadata": {},
   "source": [
    "Open `text_preprocessor.py` file and complete the `remove_stopwords()` function. This takes in a `Series` of strings and removes stopwords in the text.\n",
    "\n",
    "Implement the `remove_stopwords()` function. Inline comments should help you in completing the contents of the function.\n",
    "\n",
    "Afterwards, let's import the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcd6204a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "from text_preprocessor import remove_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20589b05",
   "metadata": {},
   "source": [
    "Remove punctuations in the texts in column `text_wo_punct` by calling the function `remove_stopwords()` and assign the return value to a new column `text_wo_stop`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86e78cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "text_wo_stop = tp.remove_stopwords(text_wo_punct )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3810f50b",
   "metadata": {},
   "source": [
    "Let's display the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6de9ee69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sprintcare I did.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  @115712 I understand. I would like to assist y...\n",
       "1      @sprintcare and how do you propose we do that\n",
       "2  @sprintcare I have sent several private messag...\n",
       "3  @115712 Please send us a Private Message so th...\n",
       "4                                 @sprintcare I did."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twcs_text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8c6504",
   "metadata": {},
   "source": [
    "Display the string without stopwords in index `18`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ee94e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'askspectrum received corporate office would like copy'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here\n",
    "text_wo_stop[18]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32785db6",
   "metadata": {},
   "source": [
    "**Checkpoint #5:** After calling the function `remove_stopwords()`, what is the string in index `18`?\n",
    "\n",
    "Answer: askspectrum received corporate office would like copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89318986",
   "metadata": {},
   "source": [
    "Display the string without stopwords in index `3000`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a3008a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'britishairways satisfactorily dm please'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here\n",
    "text_wo_stop[3000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17eed075",
   "metadata": {},
   "source": [
    "**Checkpoint #6:** After calling the function `remove_stopwords()`, what is the string in index `3000`?\n",
    "\n",
    "Answer: britishairways satisfactorily dm please"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd60ca2",
   "metadata": {},
   "source": [
    "### Removal of Frequent Words\n",
    "\n",
    "If you are working on a domain-specific corpus, most of the frequent words might not be important in processing the text data. Thus, it might be useful to remove frequent words in the given corpus. If you a technique similar to tf-idf, this is automatically taken care of."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d571d83",
   "metadata": {},
   "source": [
    "Open `text_preprocessor.py` file and complete the `get_frequent_words()` function. This returns the most frequent words in our dataset.\n",
    "\n",
    "Implement the `get_frequent_words()` function. Inline comments should help you in completing the contents of the function.\n",
    "\n",
    "Afterwards, let's import the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2845617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "from text_preprocessor import get_frequent_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6486ce86",
   "metadata": {},
   "source": [
    "Let's call the function to get the top 15 most frequent words in the texts in column `text_wo_stop`. Display the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "85fa3ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('us', 7208),\n",
       " ('please', 6590),\n",
       " ('dm', 4998),\n",
       " ('help', 4376),\n",
       " ('hi', 3758),\n",
       " ('thanks', 3594),\n",
       " ('get', 3350),\n",
       " ('sorry', 3036),\n",
       " ('amazonhelp', 2479),\n",
       " ('know', 2451),\n",
       " ('like', 2263),\n",
       " ('look', 2159),\n",
       " ('well', 2146),\n",
       " ('send', 2127),\n",
       " ('im', 2069)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here\n",
    "tp.get_frequent_words(text_wo_stop, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36eef902",
   "metadata": {},
   "source": [
    "**Checkpoint #7:** What is the most frequent word in the dataset?\n",
    "\n",
    "Answer: ('us', 7208)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d55cfc",
   "metadata": {},
   "source": [
    "**Checkpoint #8:** What is the 5th most frequent word in the dataset?\n",
    "\n",
    "Answer: ('hi', 3758)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667830b7",
   "metadata": {},
   "source": [
    "**Checkpoint #9:** What is the 10th most frequent word in the dataset?\n",
    "\n",
    "Answer: ('know', 2451)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be17df94",
   "metadata": {},
   "source": [
    "**Checkpoint #10:** What is the 15th most frequent word in the dataset?\n",
    "\n",
    "Answer: ('im', 2069)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603bc1a4",
   "metadata": {},
   "source": [
    "Open `text_preprocessor.py` file and complete the `remove_frequent_words()` function. This takes in a `Series` of strings and removes the top frequent words in the dataset.\n",
    "\n",
    "Implement the `remove_frequent_words()` function. Inline comments should help you in completing the contents of the function.\n",
    "\n",
    "Afterwards, let's import the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb44acb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "from text_preprocessor import remove_frequent_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e107e8",
   "metadata": {},
   "source": [
    "Remove the top 10 frequent words in the texts in column `text_wo_stop` by calling the function `remove_frequent_words()` and assign the return value to a new column `text_wo_freq`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aba8c537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "text_wo_freq = tp.remove_frequent_words(text_wo_stop, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f045d6b",
   "metadata": {},
   "source": [
    "Let's display the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e0525d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sprintcare I did.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  @115712 I understand. I would like to assist y...\n",
       "1      @sprintcare and how do you propose we do that\n",
       "2  @sprintcare I have sent several private messag...\n",
       "3  @115712 Please send us a Private Message so th...\n",
       "4                                 @sprintcare I did."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twcs_text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a69ce73",
   "metadata": {},
   "source": [
    "Display the string without frequent words in index `43687`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5b3ce13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tesco peter getting back'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here\n",
    "text_wo_freq[43687]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f55d3d",
   "metadata": {},
   "source": [
    "**Checkpoint #11:** After calling the function `remove_frequent_words()`, what is the string in index `43687`?\n",
    "\n",
    "Answer: tesco peter getting back"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e01209f",
   "metadata": {},
   "source": [
    "Display the string without frequent words in index `44762`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "094e8dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'askpaypal still needing sent'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here\n",
    "text_wo_freq[44762]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6aababc",
   "metadata": {},
   "source": [
    "**Checkpoint #12:** After calling the function `remove_frequent_words()`, what is the string in index `44762`?\n",
    "\n",
    "Answer: askpaypal still needing sent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052ca133",
   "metadata": {},
   "source": [
    "### Stemming\n",
    "\n",
    "Stemming is the process of reducing inflected (or sometimes derived) words to their word stem, base or root form (From [Wikipedia](https://en.wikipedia.org/wiki/Stemming)).\n",
    "\n",
    "For example, stemming will remove the suffixes in words like 'walks' and 'walking' to convert them to the root word 'walk'. But in another example, we have two words 'console' and 'consoling', the stemmer will remove the suffix and make them 'consol' which is not a proper english word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b845bfd",
   "metadata": {},
   "source": [
    "Open `text_preprocessor.py` file and complete the `stem()` function. This takes in a `Series` of strings and performs stemming to each word in the string. This uses the `PorterStemmer` from the `nltk` package.\n",
    "\n",
    "Implement the `stem()` function. Inline comments should help you in completing the contents of the function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6bc69e",
   "metadata": {},
   "source": [
    "Import the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "638b1b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "from text_preprocessor import stem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e92008",
   "metadata": {},
   "source": [
    "Perform stemming in the texts in column `text_wo_freq` by calling the function `stem()` and assign the return value to a new column `text_stem`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b97c349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "text_stem = tp.stem(text_wo_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98f692a",
   "metadata": {},
   "source": [
    "Let's display the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a8d6528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sprintcare I did.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  @115712 I understand. I would like to assist y...\n",
       "1      @sprintcare and how do you propose we do that\n",
       "2  @sprintcare I have sent several private messag...\n",
       "3  @115712 Please send us a Private Message so th...\n",
       "4                                 @sprintcare I did."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twcs_text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a4f659",
   "metadata": {},
   "source": [
    "Words like 'private' and 'propose' have their 'e' at the end chopped off due to stemming. This is not intented. Lemmatization is used in such cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d49f702",
   "metadata": {},
   "source": [
    "Display the string with stemmed words in index `18`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e0946e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'askspectrum receiv corpor offic would like copi'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here\n",
    "text_stem[18]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7fbec5",
   "metadata": {},
   "source": [
    "**Checkpoint #13:** After calling the function `stem()`, what is the string in index `18`?\n",
    "\n",
    "Answer: askspectrum receiv corpor offic would like copi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b1933f",
   "metadata": {},
   "source": [
    "Display the string with stemmed words in index `100`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5667100e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'askplayst what novemb ps plu free game'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here\n",
    "text_stem[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca3a52a",
   "metadata": {},
   "source": [
    "**Checkpoint #14:** After calling the function `stem()`, what is the string in index `100`?\n",
    "\n",
    "Answer: askplayst what novemb ps plu free game"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d996a98",
   "metadata": {},
   "source": [
    "### Lemmatization\n",
    "\n",
    "Lemmatization is similar to stemming in reducing inflected words to their word stem, but differs in the way that it makes sure the root word (also called as lemma) belongs to the language. As a result, this is generally slower than stemming process. Thus, either stemming or lemmatization can be used depending on the speed requirement.\n",
    "\n",
    "Let's download `wordnet` from the `nltk` package. This is needed for lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6373aaf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/angeloguerra/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106e5fed",
   "metadata": {},
   "source": [
    "We will use the `WordNetLemmatizer` from the `nltk` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "26b06e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46dd40c",
   "metadata": {},
   "source": [
    "Let's try to perform lemmatization on the word 'running'. This should return the root word 'run'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "80016058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'running'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('running')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afafd32",
   "metadata": {},
   "source": [
    "Notice that the lemmatizer returns the word 'running' instead of the root word 'run'. This is because the lemmatization process depends on the Part-of-Speech tag to come up with the correct lemma. \n",
    "\n",
    "Lemmatize the word 'running' again by providing the correct Part-of-Speech tag `v` for verbs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bfc1d98d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('running', 'v')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288cf71d",
   "metadata": {},
   "source": [
    "Now we are getting the root form 'run'. Thus, there is a need to provide the Part-of-Speech tag of the word along with the word for lemmatizer in `nltk`. Depending on the tag, the lemmatizer may return different results.\n",
    "\n",
    "Perform lemmatization on the word 'stripes' and check the lemma when it is both verb and noun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4d022264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma result for verb :  strip\n",
      "Lemma result for noun :  stripe\n"
     ]
    }
   ],
   "source": [
    "print('Lemma result for verb : ', lemmatizer.lemmatize('stripes', 'v'))\n",
    "print('Lemma result for noun : ', lemmatizer.lemmatize('stripes', 'n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac74248",
   "metadata": {},
   "source": [
    "Open `text_preprocessor.py` file and complete the `lemmatize()` function. This takes in a `Series` of strings and performs lemmatization to each word in the string. This uses the `WordNetLemmatizer` and the `pos_tag` from the `nltk` package.\n",
    "\n",
    "Implement the `lemmatize()` function. Inline comments should help you in completing the contents of the function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ecdcca",
   "metadata": {},
   "source": [
    "Import the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a3190302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "from text_preprocessor import lemmatize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc08d805",
   "metadata": {},
   "source": [
    "Let's download `averaged_perceptron_tagger` from the `nltk` package. We will use this to get the Part-of-Speech tag of each word in a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7e0e25f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/angeloguerra/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359a3e46",
   "metadata": {},
   "source": [
    "Perform lemmatization in the texts in column `text_wo_freq` by calling the function `lemmatize()` and assign the return value to a new column `text_lemma`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "84cf0cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "text_lemma = tp.lemmatize(text_wo_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065b7765",
   "metadata": {},
   "source": [
    "Let's display the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2279b2ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sprintcare I did.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  @115712 I understand. I would like to assist y...\n",
       "1      @sprintcare and how do you propose we do that\n",
       "2  @sprintcare I have sent several private messag...\n",
       "3  @115712 Please send us a Private Message so th...\n",
       "4                                 @sprintcare I did."
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twcs_text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdc115e",
   "metadata": {},
   "source": [
    "We can see that the trailing 'e' in the words 'propose' and 'private' is retained when we use lemmatization unlike stemming. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c20af46",
   "metadata": {},
   "source": [
    "Display the string with lemmatized words in index `49267`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d264f100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'virginatlantic propose resolve'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here\n",
    "text_lemma[49267]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64227ba",
   "metadata": {},
   "source": [
    "**Checkpoint #15:** After calling the function `lemmatize()`, what is the string in index `49267`?\n",
    "\n",
    "Answer: virginatlantic propose resolve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a851da7a",
   "metadata": {},
   "source": [
    "Display the string with lemmatized words in index `750`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "37caf6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sprintcare ive send several private message one responds'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here\n",
    "text_lemma[750]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808613cd",
   "metadata": {},
   "source": [
    "**Checkpoint #16:** After calling the function `lemmatize()`, what is the string in index `750`?\n",
    "\n",
    "Answer: sprintcare ive send several private message one responds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
